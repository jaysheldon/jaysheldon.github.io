<!DOCTYPE html>
<html>
<head>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.15.1/dist/tf.min.js"></script>

</head>
<body>
  <h1> Welcome To Eye Face </h1>
<div id="myDiv01">...</div><br>  
  
<input type=button value=run onclick="{
    run()
}"><br><br>
   
<video onplay="onPlay(this)" id="inputVideo" autoplay muted  width="640" height="480" style=" border: 1px solid #ddd;"></video><br>
<canvas id="overlay" width="640" height="480" style="position:relative; top:-487px; border: 1px solid #ddd;" ></canvas><br>
  
</body>

<script>

// JavaScript

////////////////////////// A few helper functions ///////////////////////////////////////////   
  
function resizeCanvasAndResults(dimensions, canvas, results) {
  const { width, height } = dimensions instanceof HTMLVideoElement
    ? faceapi.getMediaDimensions(dimensions)
    : dimensions
  canvas.width = width
  canvas.height = height

  return results.map(res => res.forSize(width, height))
}

  
function drawDetections(dimensions, canvas, detections) {
  const resizedDetections = resizeCanvasAndResults(dimensions, canvas, detections)
  faceapi.drawDetection(canvas, resizedDetections)
}

  
function drawLandmarks(dimensions, canvas, results, withBoxes = true) {
  const resizedResults = resizeCanvasAndResults(dimensions, canvas, results)
  if (withBoxes) {
      faceapi.drawDetection(canvas, resizedResults.map(det => det.detection))
  }
  const faceLandmarks = resizedResults.map(det => det.landmarks)
  const drawLandmarksOptions = { lineWidth: 2, drawLines: true, color: 'green' }
  faceapi.drawLandmarks(canvas, faceLandmarks, drawLandmarksOptions)
}    
    


  
////////////////////////// The 2 Main functions ///////////////////////////////////////////  
  
async function onPlay() {
   const videoEl = document.getElementById('inputVideo')
	const cat = document.getElementById('inputVideo');
	var res = model.execute({input: tf.fromPixels(cat)});
	console.log("post-calc");


   result = await faceapi.detectSingleFace(videoEl, options).withFaceLandmarks(true)
   if (result) {
       drawLandmarks(videoEl, document.getElementById('overlay'), [result], true)
     
      // Just printing the first of 68 face landmark x and y 
      document.getElementById('myDiv01').innerHTML = 'First of 68 face landmarks, x: '+ 
        Math.round(result._unshiftedLandmarks._positions[0]._x) + ', y: '+ 
        Math.round(result._unshiftedLandmarks._positions[0]._y) +'<br>' 
        
   }

    setTimeout(() => onPlay())
}

async function run() {
	const MODEL_URL = 'https://jaysheldon.github.io/faceapi/faceeye/web_model/tensorflowjs_model.pb';
	const WEIGHTS_URL = 'https://jaysheldon.github.io/faceapi/faceeye/web_model/weights_manifest.json';

	console.log("pre-calc");
	const model = await tf.loadFrozenModel(MODEL_URL, WEIGHTS_URL);

   const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
   const videoEl = document.getElementById('inputVideo')
   videoEl.srcObject = stream
}

</script>
</body>
</html>
